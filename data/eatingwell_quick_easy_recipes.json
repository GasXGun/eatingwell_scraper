import requests
from bs4 import BeautifulSoup
import json
import time
import os

# è¨­å®š HTTP è«‹æ±‚æ¨™é ­ (æ¨¡æ“¬ç€è¦½å™¨)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
# åŸºç¤ URL
BASE_URL = 'https://www.eatingwell.com'
# Quick & Easy é é¢çš„å›ºå®šè·¯å¾‘
RECIPES_BASE_PATH = '/recipes/18258/cooking-methods-styles/quick-easy/'

# --- è¼”åŠ©å‡½å¼: å–å¾—é£Ÿè­œé€£çµ ---

def get_all_recipe_links(max_pages=5):
    """å¾ Quick & Easy åˆ†é é é¢çˆ¬å–åˆå§‹é€£çµã€‚"""
    all_links = set()
    
    # è¨­ç½®æœ€å¤§åˆ†é æ•¸ï¼Œä»¥ä¾¿æŠ“å–æ›´å¤š Quick & Easy åˆ—è¡¨çš„é€£çµ
    for page_num in range(1, max_pages + 1):
        list_url = f"{BASE_URL}{RECIPES_BASE_PATH}?page={page_num}"
        # print(f"-> æ­£åœ¨çˆ¬å– Quick & Easy åˆ†é  (Page {page_num}): {list_url}")
        
        try:
            response = requests.get(list_url, headers=HEADERS, timeout=10)
            response.raise_for_status() 
            soup = BeautifulSoup(response.text, 'html.parser')
            
            recipe_card_links = soup.select('a.mntl-document-card') 
            
            if not recipe_card_links and page_num == 1:
                 # é€™è£¡å¯èƒ½éœ€è¦èª¿æ•´ max_pages çš„å€¼
                 pass
            elif not recipe_card_links:
                 break

            for link_tag in recipe_card_links:
                if 'href' in link_tag.attrs:
                    raw_url = link_tag['href'].split('?')[0] 

                    if not raw_url.startswith('http'):
                        full_url = BASE_URL + raw_url
                    else:
                        full_url = raw_url
                        
                    all_links.add(full_url)
            
            time.sleep(1) 

        except requests.exceptions.RequestException:
            break
            
    return list(all_links)

# --- æ ¸å¿ƒå‡½å¼: çˆ¬å–å–®å€‹é é¢è³‡æ–™ (åŒ…å«é£Ÿè­œæå–å’ŒåµŒå¥—é€£çµæŸ¥æ‰¾) ---

def scrape_page_content(page_url):
    """
    1. å˜—è©¦æå–å–®ä¸€é£Ÿè­œ (JSON-LD å„ªå…ˆ)ã€‚
    2. å¦‚æœå¤±æ•—ï¼Œå‰‡å˜—è©¦æå–é é¢ä¸­æ‰€æœ‰åµŒå¥—çš„ 'View Recipe' é€£çµã€‚
    
    :return: (dict or None, list) -> (é£Ÿè­œæ•¸æ“š, åµŒå¥—é€£çµåˆ—è¡¨)
    """
    
    try:
        response = requests.get(page_url, headers=HEADERS, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # --- 1. å˜—è©¦å¾ JSON-LD æå–å–®ä¸€é£Ÿè­œ ---
        schema_script = soup.find('script', {'type': 'application/ld+json'})
        if schema_script:
            try:
                data = json.loads(schema_script.text)
                data_list = data if isinstance(data, list) else [data]
                
                for item in data_list:
                    item_type = item.get("@type", [])
                    if (isinstance(item_type, list) and 'Recipe' in item_type) or (item_type == "Recipe"):
                        
                        ingredients = item.get("recipeIngredient", [])
                        # æª¢æŸ¥ï¼šåªæœ‰ç•¶æˆåŠŸæå–åˆ°æˆåˆ†æ™‚ï¼Œæ‰èªç‚ºé€™æ˜¯æœ‰æ•ˆçš„é£Ÿè­œæ•¸æ“š
                        if ingredients and len(ingredients) > 0:
                            # æå–æ‰€æœ‰æ ¸å¿ƒæ•¸æ“š
                            title = item.get("name", "N/A")
                            description = item.get("description", "N/A")
                            instructions_raw = item.get("recipeInstructions", [])
                            total_time = item.get("totalTime", "N/A")
                            
                            instructions = []
                            if isinstance(instructions_raw, list):
                                for step in instructions_raw:
                                    if isinstance(step, dict) and step.get("text"):
                                        instructions.append(step["text"].strip())
                                    elif isinstance(step, str):
                                        instructions.append(step.strip())
                            
                            print(f"   âœ… JSON-LD æå–æˆåŠŸã€‚Title: {title}")
                            return {
                                "URL": page_url,
                                "Title": title,
                                "Description": description,
                                "Ingredients": ingredients,
                                "Instructions": instructions,
                                "Total_Time_Raw": total_time 
                            }, [] # æˆåŠŸæå–é£Ÿè­œï¼Œä¸è¿”å›æ–°çš„åµŒå¥—é€£çµ

            except json.JSONDecodeError:
                # print("   âŒ éŒ¯èª¤: ç„¡æ³•è§£æ JSON-LD è…³æœ¬ã€‚")
                pass

        # --- 2. å¦‚æœä¸æ˜¯å–®ä¸€é£Ÿè­œï¼Œå˜—è©¦æå–æ‰€æœ‰åµŒå¥—çš„ 'View Recipe' é€£çµ ---
        
        # è©²é¸æ“‡å™¨é‡å° ListScTemplate é é¢ä¸­çš„ "View Recipe" æŒ‰éˆ•
        nested_links = soup.select('.mntl-sc-block-universal-featured-link--button a.mntl-sc-block-universal-featured-link__link')
        new_links = set()
        
        if nested_links:
            # é€™æ˜¯æ–‡ç« åˆ—è¡¨é é¢ï¼Œæå–æ‰€æœ‰å…§åµŒçš„é£Ÿè­œé€£çµ
            # æå–æ–‡ç« æ¨™é¡Œä½œç‚ºè­˜åˆ¥
            article_title_tag = soup.select_one('h1.article-heading') 
            article_title = article_title_tag.text.strip() if article_title_tag else "N/A Article"

            print(f"   ğŸ” ç™¼ç¾æ–‡ç« åˆ—è¡¨é é¢: {article_title}")
            for link_tag in nested_links:
                if 'href' in link_tag.attrs:
                    raw_url = link_tag['href'].split('?')[0]
                    
                    if not raw_url.startswith('http'):
                        full_url = BASE_URL + raw_url
                    else:
                        full_url = raw_url
                    
                    new_links.add(full_url)
            
            print(f"   ğŸ”— æå–åˆ° {len(new_links)} å€‹åµŒå¥—é£Ÿè­œé€£çµã€‚")
            return None, list(new_links) # è¿”å›ç©ºæ•¸æ“šå’Œæ–°çš„é€£çµåˆ—è¡¨

        # --- 3. å¦‚æœæ—¢ä¸æ˜¯é£Ÿè­œä¹Ÿä¸æ˜¯æ–‡ç« åˆ—è¡¨ (çµæ§‹ä¸åŒ¹é…æˆ–ç©ºé é¢) ---
        
        # print("   âŒ æå–å¤±æ•—: éé£Ÿè­œ/éæ–‡ç« åˆ—è¡¨ã€‚")
        return None, []

    except requests.exceptions.RequestException as e:
        # print(f"   âŒ æå– {page_url} æ™‚ç™¼ç”Ÿè«‹æ±‚éŒ¯èª¤: {e}")
        return None, []
    except Exception as e:
        # print(f"   âŒ æå– {page_url} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        return None, []

# --- ä¸»ç¨‹å¼åŸ·è¡Œ ---

def main():
    # è¨­ç½®åˆå§‹çˆ¬å–åˆ†é æ•¸é‡ (ç‚ºç¢ºä¿å»£åº¦ï¼Œæˆ‘å€‘å¤šæŠ“å¹¾é çš„åˆå§‹é€£çµ)
    MAX_INITIAL_PAGES = 5 
    
    if not os.path.exists('data'):
        os.makedirs('data')
        
    # 1. å–å¾—æ‰€æœ‰åˆå§‹é€£çµ (åŒ…å«å–®ä¸€é£Ÿè­œå’Œæ–‡ç« åˆ—è¡¨)
    initial_links = get_all_recipe_links(max_pages=MAX_INITIAL_PAGES)
    
    # 2. åˆå§‹åŒ–å¾…è™•ç†éšŠåˆ—å’Œå·²è™•ç†é›†åˆ
    # ä½¿ç”¨ set å„²å­˜ URLï¼Œé¿å…é‡è¤‡çˆ¬å–
    queue = initial_links
    visited_urls = set(initial_links)
    all_recipes_dict = {}
    
    total_processed = 0
    total_queued = len(queue)
    
    # 3. å»£åº¦å„ªå…ˆçˆ¬å–å¾ªç’°
    while queue:
        url = queue.pop(0)
        total_processed += 1
        
        print(f"\n--- è™•ç†é€²åº¦ {total_processed}/{total_queued} (å¾…è™•ç†: {len(queue)}) ---")
        
        # é€²è¡Œç¶²é æå–
        recipe, nested_links = scrape_page_content(url)
        
        if recipe:
            # æˆåŠŸæå–å–®ä¸€é£Ÿè­œï¼Œå­˜å„²
            all_recipes_dict[url] = recipe
        
        if nested_links:
            # ç™¼ç¾æ–°çš„åµŒå¥—é€£çµï¼Œå°‡å…¶åŠ å…¥éšŠåˆ—
            for link in nested_links:
                if link not in visited_urls:
                    visited_urls.add(link)
                    queue.append(link)
                    total_queued += 1 # æ›´æ–°ç¸½è¨ˆæ•¸
        
        # ç¦®è²Œå»¶é²
        time.sleep(1 + (total_processed % 5) * 0.2) 

    # 4. å„²å­˜çµæœåˆ° JSON æª”æ¡ˆ
    output_filename = 'data/eatingwell_quick_easy_recipes_full.json' 
    
    if all_recipes_dict:
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(all_recipes_dict, f, ensure_ascii=False, indent=4)
            print(f"\nğŸ‰ çˆ¬èŸ²ä»»å‹™å®Œæˆï¼å…±æ”¶é›† {len(all_recipes_dict)} ä»½é£Ÿè­œã€‚")
            print(f"è³‡æ–™å·²å„²å­˜åˆ° {output_filename}")
        except Exception as e:
            print(f"\nâŒ å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
         print("\nâŒ çˆ¬èŸ²å®Œæˆï¼Œä½†æ²’æœ‰æˆåŠŸæå–ä»»ä½•é£Ÿè­œè³‡æ–™ã€‚")

if __name__ == '__main__':
    main()